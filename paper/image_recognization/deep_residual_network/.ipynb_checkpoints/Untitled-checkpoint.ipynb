{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度残差网络的代码实现\n",
    "深度残差网络是中微软kaiming he等提出的，在ILSVRC 2015中的classification，detection，localization任务取得了冠军，且在COCO比赛上也夺冠【[论文](https://arxiv.org/abs/1512.03385)】。在这里对深度残差网络使用keras实现，这里使用的数据集是notmnist，字母A-J，十个字母的识别。\n",
    "## 1. 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+n/+pFKrSqjkQgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29f4b918828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_path='../datasets/notmnist/notMNIST_large/'\n",
    "test_path='../datasets/notmnist/notMNIST_small/'\n",
    "img_size=28\n",
    "num_channels=3\n",
    "\n",
    "# 读取文件夹图像\n",
    "def read_letters(folder, size=None):\n",
    "    image_names=os.listdir(folder,)\n",
    "    images=[]\n",
    "    for index, img_name in enumerate(image_names):\n",
    "        if size and index>size-1: break\n",
    "        image=cv2.imread(folder+img_name)\n",
    "        if not image is None: \n",
    "            images.append(image)\n",
    "    return np.array(images)\n",
    "\n",
    "A=read_letters(train_path+'A/', 100)\n",
    "print('complete!')\n",
    "plt.imshow(A[66])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [01:03,  6.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 3) (10000,)\n"
     ]
    }
   ],
   "source": [
    "def concate(x, x_):\n",
    "    if not x is None: \n",
    "        x=np.concatenate([x, x_], axis=0)\n",
    "    else: x=x_\n",
    "    return x\n",
    "\n",
    "def get_data(train_size=None, test_size=None):\n",
    "    letters=['A', 'B','C','D','E','F','G','H','I','J']\n",
    "    x_train=y_train=x_test=y_test=None\n",
    "    for index, letter in tqdm.tqdm(enumerate(letters)):\n",
    "        x_=read_letters(train_path+letter+'/', train_size)\n",
    "        x_train=concate(x_train, x_)\n",
    "        y_=np.ndarray([x_.shape[0]], dtype=np.uint8)\n",
    "        y_[:]=index\n",
    "        y_train=concate(y_train, y_) \n",
    "        x_=read_letters(test_path+letter+'/', test_size)\n",
    "        x_test=concate(x_test, x_)\n",
    "        y_=np.ndarray([x_.shape[0]], dtype=np.uint8)\n",
    "        y_[:]=index\n",
    "        y_test=concate(y_test, y_)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "    \n",
    "'''for train fast, here i use 1000 training samples per category and 200 test samples'''\n",
    "x_train, y_train, x_test, y_test = get_data(1000, 200)\n",
    "\n",
    "print(x_train.shape,y_train.shape)\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# pre process\n",
    "import keras\n",
    "\n",
    "y_train=keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test=keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPxAU4QeCIvxAUIQfCIrwA0ERfiCo/wdmsc2/GoLAjQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29f4f108b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "perm=np.random.permutation(x_train.shape[0])\n",
    "x_train=x_train[perm]\n",
    "y_train=y_train[perm]\n",
    "\n",
    "plt.imshow(x_train[8])\n",
    "plt.show()\n",
    "print(y_train[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 建立一个简单模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Activation, Input, AveragePooling2D, Add\n",
    "from keras.optimizers import Adam, rmsprop\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv_model=Sequential()\n",
    "conv_model.add(Conv2D(8, (3, 3), strides=(1, 1), padding='same', activation='relu', input_shape=(img_size, img_size, num_channels)))\n",
    "conv_model.add(Conv2D(16, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "conv_model.add(Conv2D(32, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "#conv_model.add(MaxPooling2D(pool_size=2))\n",
    "conv_model.add(Flatten())\n",
    "conv_model.add(Dense(100, activation='relu'))\n",
    "conv_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "conv_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stopper=EarlyStopping(patience=30)\n",
    "conv_model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=1000, epochs=100, verbose=1, shuffle=True, \n",
    "               callbacks=[early_stopper])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 深度卷积网络实现\n",
    "A building block:\n",
    "![residual](./images/20180213180857.png)\n",
    "我们的目标是构建这样的块，一共有两种，一种恒等映射，x; 一种非恒等，就是输入和输出的维度不一样，需要对输入进行变换wx。 （**identity & projection** shortcut） \n",
    "### (1) identity shorcut\n",
    "层顺序：conv2d -> BN -> relu，可以是任意层，注意最后一个层要残差链接后再激活函数relu输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x：输入，filters：卷积核数，kernelsize：核大小\n",
    "def identity_shortcut(x, filters, kernel_sizes):\n",
    "    last=x\n",
    "    for i, f in enumerate(filters):\n",
    "        last=Conv2D(f, kernel_sizes[i], strides=(1, 1), padding='same')(last)\n",
    "        last=BatchNormalization()(last)\n",
    "        if i<len(filters)-1: last=Activation('relu')(last)\n",
    "    #return Activation('relu')(x+last)\n",
    "    return Activation('relu')(Add()([x, last]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) projection shortcut\n",
    "与identity shortcut不一样的有两点：\n",
    "- projection中的第一层可能需要做downsampling，即stride为2\n",
    "- 最后一层残差连接，因为维度不一样，要对输入做投射到相同维度；因为经过第一层的downsampling，feature map 边大小减半。所以连接时对x(输入)做卷积操作，步数为2，核大小1,核数等于最后一层核数。 \n",
    "\n",
    "(**详细在代码或论文中展示** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def projection_shortcut(x, filters, kernel_sizes, strides=(2, 2), proj_strides=(2, 2)):\n",
    "    last=x\n",
    "    for i, f in enumerate(filters):\n",
    "        if i==0: last=Conv2D(f, kernel_sizes[i], strides=strides, padding='same')(last)\n",
    "        else: last=Conv2D(f, kernel_sizes[i], strides=(1, 1), padding='same')(last)\n",
    "        last=BatchNormalization()(last)\n",
    "        if i<len(filters)-1: last=Activation('relu')(last)\n",
    "    x= Conv2D(filters[-1], (1, 1), strides=proj_strides)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    return Activation('relu')(Add()([x, last]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ps: 这里犯了个错误，因为对keras算刚接触不久，后面的model代码报错：*'Tensor' object has no attribute '_keras_history'* ，最后发现是+法的错，在keras中不能直接相加，应该是keras中应该需要记录(\\_keras_history), 所以不支持直接相加，减法，乘法等)\n",
    "https://stackoverflow.com/questions/45030966/attributeerrortensor-object-has-no-attribute-keras-history 中：\n",
    "\n",
    "> The problem lied in the fact that using every tf operation should be encapsulated by either:\n",
    "> 1. Using keras.backend functions,\n",
    "> 2. Lambda layers,\n",
    "> 3. Designated keras functions with the same behavior.\n",
    "\n",
    "> When you are using tf operation - you are getting tf tensor object which doesn't have history field. When you use keras functions you will get keras.tensors.\n",
    "\n",
    "所以是因为+操作返回了tensorflow的tensor，从而没有history field。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) model details\n",
    "论文中网络有5个，分别为18，34，50，101和152层，具体如下表(表中后三个网络的第一个卷积层核数为256)：\n",
    "![networks](./images/20180213225351.png)\n",
    "有了两个函数后就只需跟着表建立即可，用到projection shortcut的是conv3_1, conv4_1, conv5_1。\n",
    "下面将实现50-layer："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 14, 14, 256)\n",
      "(?, 7, 7, 256)\n",
      "(?, 10)\n"
     ]
    }
   ],
   "source": [
    "inp=Input(shape=(img_size, img_size, num_channels))\n",
    "\n",
    "# out=Flatten()(inp)\n",
    "# print(out.shape)\n",
    "# model=Model(inputs=inp, outputs=out)\n",
    "\n",
    "out=Conv2D(256, 7, strides=2, padding='same')(inp)\n",
    "print(out.shape)\n",
    "out=BatchNormalization()(out)\n",
    "out=Activation('relu')(out)\n",
    "out=MaxPooling2D(pool_size=(3, 3), strides=2, padding='same')(out)\n",
    "print(out.shape)\n",
    "\n",
    "out=identity_shortcut(out, [64, 64, 256], [1, 3, 1])\n",
    "out=identity_shortcut(out, [64, 64, 256], [1, 3, 1])\n",
    "out=identity_shortcut(out, [64, 64, 256], [1, 3, 1])\n",
    "\n",
    "out=projection_shortcut(out, [128, 128, 512], [1, 3, 1])\n",
    "out=identity_shortcut(out, [128, 128, 512], [1, 3, 1])\n",
    "out=identity_shortcut(out, [128, 128, 512], [1, 3, 1])\n",
    "out=identity_shortcut(out, [128, 128, 512], [1, 3, 1])\n",
    "\n",
    "out=projection_shortcut(out, [256, 256, 1024], [1, 3, 1])\n",
    "out=identity_shortcut(out, [256, 256, 1024], [1, 3, 1])\n",
    "out=identity_shortcut(out, [256, 256, 1024], [1, 3, 1])\n",
    "out=identity_shortcut(out, [256, 256, 1024], [1, 3, 1])\n",
    "out=identity_shortcut(out, [256, 256, 1024], [1, 3, 1])\n",
    "out=identity_shortcut(out, [256, 256, 1024], [1, 3, 1])\n",
    "\n",
    "out=projection_shortcut(out, [512, 512, 2048], [1, 3, 1])\n",
    "out=identity_shortcut(out, [512, 512, 2048], [1, 3, 1])\n",
    "out=identity_shortcut(out, [512, 512, 2048], [1, 3, 1])\n",
    "\n",
    "out=AveragePooling2D(padding='same')(out)\n",
    "out=Flatten()(out)\n",
    "print(out1.shape)\n",
    "out=Dense(10, activation='softmax')(out)\n",
    "model=Model(inputs=inp, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-30e85abf6d30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mearly_stopper\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=200, epochs=100, verbose=2, shuffle=True, \n\u001b[0;32m      4\u001b[0m                callbacks=[early_stopper])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stopper=EarlyStopping(patience=10)\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=200, epochs=100, verbose=2, shuffle=True, \n",
    "               callbacks=[early_stopper])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "至此，深度卷积神经网络的框架就实现了，不过论文中的数据增强，crops，ensemble等就没有去做实现。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
